env:
  env_name: antmaze
  task_name: gcrl
  max_episode_length: 500
  exp_name: q1_ant_normal
  atari: true
  goal_dist: normal
  goal_frequency: 10
  goal_indicies:
  - 0
  - 1
  uniform_bounds:
  - - -4
    - -4
  - - 20
    - 4
  gaussian_bounds:
  - - 0
    - 8
  - - 4
    - 4
  k: 15
alg:
  double_q: true
  batch_size: 4096
  train_batch_size: 4096
  eval_batch_size: 4096
  num_agent_train_steps_per_iter: 1
  num_critic_updates_per_agent_update: 16
  use_gpu: false
  gpu_id: 0
  rl_alg: pg
  learning_starts: 1024
  learning_freq: 1
  target_update_freq: 1
  exploration_schedule: 0
  optimizer_spec: 0
  replay_buffer_size: 100000
  frame_history_len: 1
  gamma: 0.95
  critic_learning_rate: 0.001
  learning_rate: 0.0003
  ob_dim: 0
  ac_dim: 0
  batch_size_initial: 0
  discrete: true
  grad_norm_clipping: true
  n_iter: 10000
  polyak_avg: 0.01
  td3_target_policy_noise: 0.1
  sac_entropy_coeff: 0.2
  policy_std: 0.05
  use_baseline: true
  gae_lambda: 0.9
  standardize_advantages: true
  reward_to_go: false
  nn_baseline: true
  on_policy: true
  learn_policy_std: false
  deterministic: false
  network:
    layer_sizes:
    - 64
    - 32
    activations:
    - leaky_relu
    - leaky_relu
    output_activation: identity
logging:
  video_log_freq: 100
  scalar_log_freq: 10
  save_params: false
  random_seed: 1234
  logdir: ''
  debug: false
